{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matminer.featurizers.composition.composite import ElementProperty\n",
    "from pymatgen.core.composition import Composition\n",
    "import matminer.featurizers.composition as cf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "\n",
    "ep = cf.ElementProperty.from_preset(preset_name=\"magpie\", impute_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "training_set = Dataset.from_json(\"../prompt_type_4/real_train_dataset_with_mpid.json\")\n",
    "validation_set = Dataset.from_json(\"../prompt_type_4/real_val_dataset_with_mpid.json\")\n",
    "with open('../prompt_type_4/ec_desc_test_dataset_with_mpid.json') as f:\n",
    "    test_set = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9498\n",
      "500\n",
      "522\n"
     ]
    }
   ],
   "source": [
    "print(len(training_set))\n",
    "print(len(validation_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_material_description(text):\n",
    "    pattern = r\"The material(.*?)with\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        print(f\"Pattern not found in text: {text}\")\n",
    "        return \"No description found\"\n",
    "\n",
    "train_desc = [extract_material_description(d['input']) for d in training_set]\n",
    "val_desc = [extract_material_description(d['input']) for d in validation_set]\n",
    "test_desc = [extract_material_description(d['input']) for d in test_set]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ElementProperty: 100%|██████████| 9498/9498 [05:47<00:00, 27.30it/s]\n",
      "ElementProperty: 100%|██████████| 500/500 [00:13<00:00, 36.38it/s] \n",
      "ElementProperty: 100%|██████████| 522/522 [00:16<00:00, 32.34it/s]\n"
     ]
    }
   ],
   "source": [
    "training_compostion = [Composition(comp) for comp in train_desc]\n",
    "val_compostion = [Composition(comp) for comp in val_desc]\n",
    "test_compostion = [Composition(comp) for comp in test_desc]\n",
    "training_features = ep.featurize_many(training_compostion)\n",
    "validation_features = ep.featurize_many(val_compostion)\n",
    "test_features = ep.featurize_many(test_compostion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices with NaN in training features: []\n",
      "Indices with NaN in validation features: []\n",
      "Indices with NaN in test features: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Find indices where any element in the feature list is NaN\n",
    "def find_nan_indices(features_list):\n",
    "    nan_indices = []\n",
    "    for i, f in enumerate(features_list):\n",
    "        if np.isnan(f).any():\n",
    "            nan_indices.append(i)\n",
    "    \n",
    "    return nan_indices\n",
    "\n",
    "print(\"Indices with NaN in training features:\", find_nan_indices(training_features))\n",
    "print(\"Indices with NaN in validation features:\", find_nan_indices(validation_features))\n",
    "print(\"Indices with NaN in test features:\", find_nan_indices(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "training_elastic_tensor = [np.array(eval(tensor['output'])).flatten() for tensor in training_set]\n",
    "val_elastic_tensor = [np.array(eval(tensor['output'])).flatten() for tensor in validation_set]\n",
    "test_elastic_tensor = [np.array(eval(tensor['output'])).flatten() for tensor in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9498\n",
      "500\n",
      "522\n"
     ]
    }
   ],
   "source": [
    "print(len(training_elastic_tensor))\n",
    "print(len(val_elastic_tensor))\n",
    "print(len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save training data\n",
    "training_data = [{\n",
    "    \"material_id\": entry[\"material_id\"],\n",
    "    \"features\": str(features),\n",
    "    \"elastic_tensor\": str(tensor.tolist())\n",
    "} for entry, features, tensor in zip(training_set, training_features, training_elastic_tensor)]\n",
    "with open(\"training_data.json\", \"w\") as f:\n",
    "    json.dump(training_data, f)\n",
    "\n",
    "# Save validation data\n",
    "validation_data = [{\n",
    "    \"material_id\": entry[\"material_id\"],\n",
    "    \"features\": str(features),\n",
    "    \"elastic_tensor\": str(tensor.tolist())\n",
    "} for entry, features, tensor in zip(validation_set, validation_features, val_elastic_tensor)]\n",
    "with open(\"validation_data.json\", \"w\") as f:\n",
    "    json.dump(validation_data, f)\n",
    "\n",
    "# Save test data\n",
    "test_data = [{\n",
    "    \"material_id\": entry[\"material_id\"],\n",
    "    \"features\": str(features),\n",
    "    \"elastic_tensor\": str(tensor.tolist())\n",
    "} for entry, features, tensor in zip(test_set, test_features, test_elastic_tensor)]\n",
    "with open(\"test_data.json\", \"w\") as f:\n",
    "    json.dump(test_data, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ec-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
